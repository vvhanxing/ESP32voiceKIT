{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from depth_anything_v2.dpt import DepthAnythingV2\n",
    "import vtk\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = DepthAnythingV2(encoder='vitb', features=128, out_channels=[96, 192, 384, 768])\n",
    "model.load_state_dict(torch.load('./checkpoints/depth_anything_v2_vitb.pth', map_location='cuda:0')) #cpu\n",
    "\n",
    "\n",
    "# model = DepthAnythingV2(encoder='vits', features=64, out_channels=[48, 96, 192, 384])\n",
    "# model.load_state_dict(torch.load('./checkpoints/depth_anything_v2_vits.pth', map_location='cuda:0'))\n",
    "\n",
    "def pic23d(pic_path,save_path):\n",
    "    model.cuda().eval()   #   cpu model.eval() \n",
    "\n",
    "    raw_img = cv2.imread(pic_path)  \n",
    "    height, width = raw_img.shape[:2]  \n",
    "    target_height = 600  \n",
    "    scale_ratio = target_height / height  \n",
    "    target_width = int(width * scale_ratio)  \n",
    "    raw_img = cv2.resize(raw_img, (target_width, target_height))  \n",
    "\n",
    "\n",
    "    depth = model.infer_image(raw_img) # HxW raw depth map\n",
    "\n",
    "\n",
    "\n",
    "    depth_normalized = cv2.normalize(depth, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)  \n",
    "    depth_display = (depth_normalized * 255).astype(np.uint8)  # 转换为8位图像以便显示  \n",
    "    cv2.imwrite('./depth_map.png', depth_display)  \n",
    "\n",
    "    fx = 50  # 焦距x  \n",
    "    fy = 50# 焦距y  \n",
    "    cx = raw_img.shape[1] / 2.0  # 光心x  \n",
    "    cy = raw_img.shape[0] / 2.0  # 光心y  \n",
    "    height, width = raw_img.shape[:2]  \n",
    "    \n",
    "    # 推断深度图  \n",
    "    depth_ = depth_display/255\n",
    "    # 深度图可能需要归一化或转换到实际的深度值，这里假设它已经是所需的格式  \n",
    "    \n",
    "    # 创建一个空的数组来存储空间位置坐标  \n",
    "    pos = np.zeros((height * width, 3), dtype=np.float32)  \n",
    "    \n",
    "    # 遍历深度图的每个像素  \n",
    "    for v in range(height):  \n",
    "        for u in range(width):  \n",
    "            d = depth_[v, u]  # 获取深度值  \n",
    "            # 计算空间坐标  \n",
    "            X = (u - cx) * 1/ fx  \n",
    "            Y = (v - cy)  * 1/ fy  \n",
    "            Z = d  *6\n",
    "            # 将坐标存储到pos数组中  \n",
    "            idx = v * width + u  \n",
    "            pos[idx] = [X, Y, Z]  \n",
    "    \n",
    "    # 现在pos数组包含了深度图上每个点的空间位置坐标\n",
    "\n",
    "\n",
    "    with open(\"a.obj\",\"w\") as t:\n",
    "        t.writelines(\"mtllib my_mtl.mtl\"+\"\\n\")\n",
    "            \n",
    "        for l in pos:\n",
    "            L = \"v \"+str(l[0])+\" \"+str(l[1])+\" \"+str(l[2])+\"\\n\"\n",
    "            t.writelines(L )\n",
    "        \n",
    "        w_x = np.asarray([np.linspace(0.0, 1.0, num=width)]*height).reshape(width*height)\n",
    "        h_y = np.asarray([np.linspace(1.0, 0.0, num=height)]*width).T.reshape(width*height)\n",
    "        t_array_ = np.stack([w_x,h_y],axis=1)\n",
    "\n",
    "\n",
    "        for i,j in t_array_:\n",
    "            L = \"vt \" +str(i)+\" \"+str(j) +\"\\n\"\n",
    "            t.writelines(L )                \n",
    "    #  \n",
    "    #          \n",
    "        t.writelines(\"\\nusemtl my_mtl\\n\" )              \n",
    "        b = np.array(range(height * width)).reshape([ height ,width])\n",
    "        print(b.shape)  \n",
    "                \n",
    "        for i in range(1,b.shape[0]-1):\n",
    "            for j in range(1,b.shape[1]-1):\n",
    "                p = [ b[i,j] , b[i+1,j],b[i+1,j+1],b[i,j+1]]\n",
    "        \n",
    "                L = \"f \"+str(p[0])+\"/\"+ str(p[0])+\" \"+str(p[1])+\"/\"+ str(p[1])+\" \"+str(p[2])+\"/\"+ str(p[2])+\" \"+str(p[3])+\"/\"+ str(p[3])+\"\\n\"\n",
    "                t.writelines(L )\n",
    "            \n",
    "\n",
    "\n",
    "    with open(\"my_mtl.mtl\",\"w\") as m:  \n",
    "        m.writelines(\n",
    "    f\"\"\"\n",
    "    newmtl my_mtl\n",
    "    Ka 1 1 1\n",
    "    Kd 1 1 1\n",
    "    d 1\n",
    "    Ns 0\n",
    "    illum 1\n",
    "    map_Kd {pic_path}\n",
    "    \"\"\"\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def render_and_save_images(obj_file,  output_file, image_size=(800, 800)):\n",
    "        # 读取模型\n",
    "        reader = vtk.vtkOBJReader()\n",
    "        reader.SetFileName(obj_file)\n",
    "        reader.Update()\n",
    "\n",
    "        # 创建一个映射器\n",
    "        mapper = vtk.vtkPolyDataMapper()\n",
    "        mapper.SetInputConnection(reader.GetOutputPort())\n",
    "\n",
    "        # 创建一个演员\n",
    "        actor = vtk.vtkActor()\n",
    "        actor.SetMapper(mapper)\n",
    "\n",
    "        # 读取贴图文件\n",
    "        texture = vtk.vtkTexture()\n",
    "        texture_reader = vtk.vtkJPEGReader()  # 假设贴图为JPEG格式\n",
    "        texture_reader.SetFileName(pic_path)  # 根据.mtl文件中的路径设置\n",
    "        texture_reader.Update()\n",
    "        texture.SetInputConnection(texture_reader.GetOutputPort())\n",
    "        \n",
    "        # 将贴图应用到演员\n",
    "        actor.SetTexture(texture)\n",
    "        actor.SetOrientation(0,0,0)\n",
    "\n",
    "        # 创建渲染窗口\n",
    "        render_window = vtk.vtkRenderWindow()\n",
    "        render_window.SetSize(image_size[0], image_size[1])  # 设置渲染窗口大小 \n",
    "\n",
    "        # 创建左右视角的渲染器\n",
    "        total_pic_count = 36\n",
    "        renderers = []\n",
    "        for i in range(total_pic_count):\n",
    "            renderer = vtk.vtkRenderer()\n",
    "            render_window.AddRenderer(renderer)\n",
    "            renderers.append(renderer)\n",
    "            # 禁用光照\n",
    "            renderer.SetAmbient(100.0, 100.0, 100.0)  # 设置环境光\n",
    "            actor.GetProperty().SetLighting(False)\n",
    "            # 设置摄像机\n",
    "            camera = vtk.vtkCamera()\n",
    "            \n",
    "            camera.SetFocalPoint(0, 0, 0)\n",
    "            # if i == 0:  # 左视角\n",
    "            #     camera.SetPosition(-2, 0, 30)  # 可以根据需要调整位置\n",
    "            #     camera.SetViewUp(0, -1, 0)\n",
    "            # else:  # 右视角\n",
    "            #     camera.SetPosition(2, 0, 30)  # 右视角位置\n",
    "            #     camera.SetViewUp(0, -1, 0)\n",
    "\n",
    "      \n",
    "            camera.SetPosition(-9+i*0.5, 0, 25)  # 可以根据需要调整位置\n",
    "            camera.SetViewUp(0, -1, 0)\n",
    "\n",
    "            renderer.SetActiveCamera(camera)\n",
    "\n",
    "            # 添加演员到渲染器\n",
    "            renderer.AddActor(actor)\n",
    "            renderer.SetBackground(0.0, 0.0, 0.0)  # 背景颜色\n",
    "\n",
    "            # 渲染\n",
    "            render_window.Render()\n",
    "\n",
    "            # 保存图像\n",
    "            window_to_image_filter = vtk.vtkWindowToImageFilter()\n",
    "            window_to_image_filter.SetInput(render_window)\n",
    "            window_to_image_filter.ReadFrontBufferOff()  # 读取后台缓冲区\n",
    "            window_to_image_filter.Update()\n",
    "\n",
    "            writer = vtk.vtkPNGWriter()\n",
    "            writer.SetFileName(save_path.replace(\"_/\",f\"{i+1}/\"))\n",
    "        \n",
    "            writer.SetInputConnection(window_to_image_filter.GetOutputPort())\n",
    "            writer.Write()\n",
    "\n",
    "    \n",
    "\n",
    "    render_and_save_images('a.obj',  'output.png')\n",
    "\n",
    "\n",
    "# pic_path = \"./37.jpg\"\n",
    "# save_path = \"./1.png\"\n",
    "# pic23d(pic_path,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n",
      "(600, 337)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 55\u001b[0m\n\u001b[0;32m     53\u001b[0m video_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./video2.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# 视频文件路径\u001b[39;00m\n\u001b[0;32m     54\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/Administrator/Pictures/blender_gif/\u001b[39m\u001b[38;5;124m'\u001b[39m    \u001b[38;5;66;03m# 输出文件夹路径\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m \u001b[43msave_frames_from_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[18], line 41\u001b[0m, in \u001b[0;36msave_frames_from_video\u001b[1;34m(video_path, output_folder, num_frames_range)\u001b[0m\n\u001b[0;32m     36\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mimwrite(frame_filename, frame)\n\u001b[0;32m     39\u001b[0m         save_path \u001b[38;5;241m=\u001b[39m frame_filename\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblender_gif/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblender_gif/_/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 41\u001b[0m         \u001b[43mpic23d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m cap\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# 释放视频捕获对象\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m已保存 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mframe_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 帧到 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[17], line 60\u001b[0m, in \u001b[0;36mpic23d\u001b[1;34m(pic_path, save_path)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m pos:\n\u001b[0;32m     59\u001b[0m     L \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(l[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(l[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(l[\u001b[38;5;241m2\u001b[39m])\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwritelines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m w_x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray([np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, num\u001b[38;5;241m=\u001b[39mwidth)]\u001b[38;5;241m*\u001b[39mheight)\u001b[38;5;241m.\u001b[39mreshape(width\u001b[38;5;241m*\u001b[39mheight)\n\u001b[0;32m     63\u001b[0m h_y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray([np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, num\u001b[38;5;241m=\u001b[39mheight)]\u001b[38;5;241m*\u001b[39mwidth)\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mreshape(width\u001b[38;5;241m*\u001b[39mheight)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def save_frames_from_video(video_path, output_folder, num_frames_range=[0,100]):\n",
    "    # 创建输出文件夹\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # 打开视频文件\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # 检查视频是否成功打开\n",
    "    if not cap.isOpened():\n",
    "        print(\"无法打开视频文件\")\n",
    "        return\n",
    "\n",
    "    frame_count = 0\n",
    "\n",
    "\n",
    "    for i in range(0,36):\n",
    "        save_path = f\"C:/Users/Administrator/Pictures/blender_gif/{i+1}/\"\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    #while (frame_count >= num_frames_range[0] and frame_count < num_frames_range[1]) :\n",
    "    # for i in range(num_frames_range[0],num_frames_range[1]):\n",
    "    pic_count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()  # 读取帧\n",
    "        if not ret:\n",
    "            break  # 如果没有更多帧，退出循环\n",
    "        frame_count += 1\n",
    "        if  (frame_count >= num_frames_range[0] and frame_count < num_frames_range[1]) :\n",
    "            pic_count+=1\n",
    "\n",
    "            # 保存帧为图像文件\n",
    "            frame_filename = os.path.join(output_folder, f'{pic_count}.jpg')\n",
    "            cv2.imwrite(frame_filename, frame)\n",
    "            \n",
    "\n",
    "            save_path = frame_filename.replace(\"blender_gif/\",\"blender_gif/_/\")\n",
    "\n",
    "            pic23d(frame_filename,save_path)\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    cap.release()  # 释放视频捕获对象\n",
    "    print(f'已保存 {frame_count} 帧到 {output_folder}')\n",
    "\n",
    "\n",
    "\n",
    "# 使用示例\n",
    "video_file = './video2.mp4'  # 视频文件路径\n",
    "output_dir = 'C:/Users/Administrator/Pictures/blender_gif/'    # 输出文件夹路径\n",
    "save_frames_from_video(video_file, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "def upload_pic(pic_file_name, save_base=\"index.bin\"):\n",
    "    im = Image.open(pic_file_name)\n",
    "    \n",
    "    # Adjust the image size while maintaining the aspect ratio\n",
    "    original_width, original_height = im.size\n",
    "    target_height = 240\n",
    "    target_width = int((target_height / original_height) * original_width)\n",
    "    im = im.resize((target_width, target_height))  # Use LANCZOS filter for better quality\n",
    "\n",
    "    # Optionally, convert to RGB if the image has an alpha channel\n",
    "    if im.mode in (\"RGBA\", \"LA\") or (im.mode == \"P\" and \"transparency\" in im.info):\n",
    "        im = im.convert(\"RGB\")\n",
    "\n",
    "    # Save as a binary file (using JPEG with adjustable quality)\n",
    "    img_byte = BytesIO()\n",
    "    im.save(img_byte, format='JPEG', quality=100)  # Adjust quality as needed\n",
    "    img_data = img_byte.getvalue()\n",
    "\n",
    "    # Write to binary file\n",
    "    with open(save_base, \"wb\") as f:\n",
    "        f.write(img_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pic_path = \"C:/Users/Administrator/Pictures/blender_gif/\"\n",
    "\n",
    " \n",
    "for i in range(1,37):\n",
    "    for pic in os.listdir(pic_path+\"/\"+str(i)):\n",
    "        if \".jpg\" in pic or \".png\" in pic:\n",
    "            # print(pic_path+pic)\n",
    "            if not os.path.exists(\"D:/move2/\"+str(i)+\"/\"):\n",
    "                os.mkdir(\"D:/move2/\"+str(i)+\"/\")\n",
    "            upload_pic(pic_path+\"/\"+str(i)+\"/\"+pic,\"D:/move2/\"+str(i)+\"/\"+str(int(pic.split(\".\")[0]))+\".bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
