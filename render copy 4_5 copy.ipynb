{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "xFormers not available\n",
      "xFormers not available\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from depth_anything_v2.dpt import DepthAnythingV2\n",
    "import vtk\n",
    "from PIL import Image\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 01:19:20,630 - modelscope - WARNING - Authentication has expired, please re-login with modelscope login --token \"YOUR_SDK_TOKEN\" if you need to access private models or datasets.\n",
      "2024-10-14 01:19:21,815 - modelscope - WARNING - Model revision not specified, use revision: v1.0.0\n",
      "2024-10-14 01:19:22,330 - modelscope - INFO - initiate model from C:\\Users\\Administrator\\.cache\\modelscope\\hub\\damo\\cv_fft_inpainting_lama\n",
      "2024-10-14 01:19:22,346 - modelscope - INFO - initiate model from location C:\\Users\\Administrator\\.cache\\modelscope\\hub\\damo\\cv_fft_inpainting_lama.\n",
      "2024-10-14 01:19:22,347 - modelscope - INFO - initialize model from C:\\Users\\Administrator\\.cache\\modelscope\\hub\\damo\\cv_fft_inpainting_lama\n",
      "2024-10-14 01:19:22,347 - modelscope - INFO - BaseInpaintingTrainingModule init called, predict_only is False\n",
      "2024-10-14 01:19:22,801 - modelscope - INFO - BaseInpaintingTrainingModule init done\n",
      "2024-10-14 01:19:22,801 - modelscope - INFO - loading pretrained model from C:\\Users\\Administrator\\.cache\\modelscope\\hub\\damo\\cv_fft_inpainting_lama\\pytorch_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights for net_encoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 01:19:23,118 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-10-14 01:19:23,118 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-10-14 01:19:23,118 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': 'C:\\\\Users\\\\Administrator\\\\.cache\\\\modelscope\\\\hub\\\\damo\\\\cv_fft_inpainting_lama'}. trying to build by task and model information.\n",
      "2024-10-14 01:19:23,118 - modelscope - WARNING - No preprocessor key ('FFTInpainting', 'image-inpainting') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "2024-10-14 01:19:23,149 - modelscope - INFO - loading model from dir C:\\Users\\Administrator\\.cache\\modelscope\\hub\\damo\\cv_fft_inpainting_lama\n",
      "2024-10-14 01:19:23,150 - modelscope - INFO - BaseInpaintingTrainingModule init called, predict_only is True\n",
      "2024-10-14 01:19:23,280 - modelscope - INFO - BaseInpaintingTrainingModule init done\n",
      "2024-10-14 01:19:23,280 - modelscope - INFO - loading pretrained model from C:\\Users\\Administrator\\.cache\\modelscope\\hub\\damo\\cv_fft_inpainting_lama\\pytorch_model.pt\n",
      "2024-10-14 01:19:23,597 - modelscope - INFO - loading model done, refinement is set to False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import cv2\n",
    "from modelscope.outputs import OutputKeys\n",
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "inpainting = pipeline(Tasks.image_inpainting, model='damo/cv_fft_inpainting_lama')\n",
    "def refine_pic(input_location,output_path):\n",
    "    input_mask_location = input_location.replace(\".png\",\"_mask.png\")\n",
    "\n",
    "    input = {\n",
    "            'img':input_location,\n",
    "            'mask':input_mask_location,\n",
    "    }\n",
    "\n",
    "    \n",
    "    result = inpainting(input)\n",
    "    vis_img = result[OutputKeys.OUTPUT_IMG]\n",
    "    cv2.imwrite(output_path, vis_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "def adjust_contrast_if_brightness_high(image_path, output_path, brightness_threshold=0.1, contrast_factor=1000):\n",
    "    # 打开图片\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    # 计算图片亮度\n",
    "    brightness_enhancer = ImageEnhance.Brightness(img)\n",
    "    brightness = brightness_enhancer.enhance(1.0)\n",
    "    brightness_value = brightness.convert('L').point(lambda x: x / 255.0, 'F').getextrema()[1]\n",
    "\n",
    "    # 如果亮度大于阈值，增加对比度\n",
    "    if brightness_value > brightness_threshold:\n",
    "        contrast_enhancer = ImageEnhance.Contrast(img)\n",
    "        img = contrast_enhancer.enhance(contrast_factor)\n",
    "    \n",
    "    # 保存调整后的图片\n",
    "    img.save(output_path)\n",
    "\n",
    "# 示例使用\n",
    "# input_image = 'view_2_mask.png'   # 输入图片路径\n",
    "# output_image = 'view_2_mask.png' # 输出图片路径\n",
    "# adjust_contrast_if_brightness_high(input_image, output_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = DepthAnythingV2(encoder='vitb', features=128, out_channels=[96, 192, 384, 768])\n",
    "model.load_state_dict(torch.load('./checkpoints/depth_anything_v2_vitb.pth', map_location='cuda:0')) #cpu\n",
    "\n",
    "\n",
    "# model = DepthAnythingV2(encoder='vits', features=64, out_channels=[48, 96, 192, 384])\n",
    "# model.load_state_dict(torch.load('./checkpoints/depth_anything_v2_vits.pth', map_location='cuda:0'))\n",
    "\n",
    "def pic23d(pic_name,path,depth_hight = 10):\n",
    "    model.cuda().eval()   #   cpu model.eval() \n",
    "    if \".png\"in pic_name or \".webp\" in pic_name:\n",
    "        image = Image.open(pic_name)  # 或者 \"example.png\"\n",
    "\n",
    "        # 转换并保存为 JPG 格式\n",
    "        pic_name = pic_name.replace(\".webp\",\".jpg\").replace(\".png\",\".jpg\")\n",
    "        image.convert(\"RGB\").save(pic_name, \"JPEG\")\n",
    "    raw_img = cv2.imread(path+pic_name)  \n",
    "    height, width = raw_img.shape[:2]  \n",
    "    target_height = 800  \n",
    "    scale_ratio = target_height / height  \n",
    "    target_width = int(width * scale_ratio)  \n",
    "    raw_img = cv2.resize(raw_img, (target_width, target_height))  \n",
    "\n",
    "\n",
    "    depth = model.infer_image(raw_img) # HxW raw depth map\n",
    "\n",
    "\n",
    "\n",
    "    depth_normalized = cv2.normalize(depth, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)  \n",
    "    depth_display = (depth_normalized * 255).astype(np.uint8)  # 转换为8位图像以便显示  \n",
    "    cv2.imwrite('./depth_map.png', depth_display)  \n",
    "\n",
    "    fx = 50*4  # 焦距x  \n",
    "    fy = 50*4# 焦距y  \n",
    "    cx = raw_img.shape[1] / 2.0  # 光心x  \n",
    "    cy = raw_img.shape[0] / 2.0  # 光心y  \n",
    "    height, width = raw_img.shape[:2]  \n",
    "    \n",
    "    # 推断深度图  \n",
    "    depth_ = depth_display/255\n",
    "    # 深度图可能需要归一化或转换到实际的深度值，这里假设它已经是所需的格式  \n",
    "    \n",
    "    # 创建一个空的数组来存储空间位置坐标  \n",
    "    pos = np.zeros((height * width, 3), dtype=np.float32)  \n",
    "    \n",
    "    # 遍历深度图的每个像素  \n",
    "    # Calculate indices for each pixel\n",
    "    v_indices,u_indices = np.indices(depth_.shape)\n",
    "\n",
    "    # Calculate spatial coordinates using vectorized operations\n",
    "    X = (u_indices - cx)*(3-depth_) / fx\n",
    "    Y = (v_indices - cy)*(3-depth_) / fy\n",
    "    Z = depth_ * depth_hight\n",
    "\n",
    "    # Stack the coordinates into a single array\n",
    "    pos = np.stack((X, Y, Z), axis=-1).reshape(-1, 3)\n",
    "    \n",
    "    # 现在pos数组包含了深度图上每个点的空间位置坐标\n",
    "    # 计算面的面积\n",
    "    def calculate_face_areas(pos, indices):\n",
    "        areas = []\n",
    "        for idx in indices:\n",
    "            p0, p1, p2, p3 = pos[idx]\n",
    "            # 计算两个三角形的面积\n",
    "            v1 = p1 - p0\n",
    "            v2 = p2 - p0\n",
    "            v3 = p3 - p0\n",
    "            area1 = np.linalg.norm(np.cross(v1, v2)) / 2.0\n",
    "            area2 = np.linalg.norm(np.cross(v2, v3)) / 2.0\n",
    "            areas.append(area1 + area2)\n",
    "        return np.array(areas)\n",
    "    all_face = False\n",
    "    if  all_face == True:\n",
    "        with open(\"a.obj\",\"w\") as t:\n",
    "            t.writelines(\"mtllib my_mtl.mtl\"+\"\\n\")\n",
    "                \n",
    "            for l in pos:\n",
    "                L = \"v \"+str(l[0])+\" \"+str(l[1])+\" \"+str(l[2])+\"\\n\"\n",
    "                t.writelines(L )\n",
    "            \n",
    "            w_x = np.asarray([np.linspace(0.0, 1.0, num=width)]*height).reshape(width*height)\n",
    "            h_y = np.asarray([np.linspace(1.0, 0.0, num=height)]*width).T.reshape(width*height)\n",
    "            t_array_ = np.stack([w_x,h_y],axis=1)\n",
    "\n",
    "\n",
    "            for i,j in t_array_:\n",
    "                L = \"vt \" +str(i)+\" \"+str(j) +\"\\n\"\n",
    "                t.writelines(L )                \n",
    "        #  \n",
    "        #          \n",
    "            t.writelines(\"\\nusemtl my_mtl\\n\" )              \n",
    "            b = np.array(range(height * width)).reshape([ height ,width])\n",
    "            print(b.shape)  \n",
    "\n",
    "\n",
    "            for i in range(1,b.shape[0]-1):\n",
    "                for j in range(1,b.shape[1]-1):\n",
    "                    p = [ b[i,j] , b[i+1,j],b[i+1,j+1],b[i,j+1]]\n",
    "            \n",
    "                    L = \"f \"+str(p[0])+\"/\"+ str(p[0])+\" \"+str(p[1])+\"/\"+ str(p[1])+\" \"+str(p[2])+\"/\"+ str(p[2])+\" \"+str(p[3])+\"/\"+ str(p[3])+\"\\n\"\n",
    "                    t.writelines(L )\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "    #############################\n",
    "        # 在生成面之后添加以下代码\n",
    "        # 假设 b 是面索引的二维数组\n",
    "        w_x = np.asarray([np.linspace(0.0, 1.0, num=width)]*height).reshape(width*height)\n",
    "        h_y = np.asarray([np.linspace(1.0, 0.0, num=height)]*width).T.reshape(width*height)\n",
    "        t_array_ = np.stack([w_x,h_y],axis=1)\n",
    "\n",
    "        b = np.array(range(height * width)).reshape([ height ,width])\n",
    "        face_indices = []\n",
    "        for i in range(1, b.shape[0]-1):\n",
    "            for j in range(1, b.shape[1]-1):\n",
    "                p = [b[i,j], b[i+1,j], b[i+1,j+1], b[i,j+1]]\n",
    "                face_indices.append(p)\n",
    "\n",
    "        face_indices = np.array(face_indices)\n",
    "\n",
    "        # 计算面面积\n",
    "        areas = calculate_face_areas(pos, face_indices)\n",
    "\n",
    "        # 删除面积大于0.02的面\n",
    "        valid_indices = areas <= 0.01\n",
    "        filtered_face_indices = face_indices[valid_indices]\n",
    "\n",
    "        # 更新OBJ文件生成\n",
    "        with open(\"filtered_model.obj\", \"w\") as t:\n",
    "            t.writelines(\"mtllib my_mtl.mtl\" + \"\\n\")\n",
    "\n",
    "            for l in pos:\n",
    "                L = \"v \" + str(l[0]) + \" \" + str(l[1]) + \" \" + str(l[2]) + \"\\n\"\n",
    "                t.writelines(L)\n",
    "\n",
    "            # UV 坐标\n",
    "            for i, j in t_array_:\n",
    "                L = \"vt \" + str(i) + \" \" + str(j) + \"\\n\"\n",
    "                t.writelines(L)\n",
    "\n",
    "            t.writelines(\"\\nusemtl my_mtl\\n\")\n",
    "\n",
    "            # 重新写入面\n",
    "            for idx in filtered_face_indices:\n",
    "                p = [idx[0], idx[1], idx[2], idx[3]]\n",
    "                L = \"f \" + \" \".join(f\"{i + 1}/{i + 1}\" for i in p) + \"\\n\"  # 注意 OBJ 文件索引从1开始\n",
    "                t.writelines(L)\n",
    "\n",
    "#######################\n",
    "\n",
    "        valid_indices = areas > 0.01\n",
    "        filtered_face_indices = face_indices[valid_indices]\n",
    "\n",
    "        # 更新OBJ文件生成\n",
    "        with open(\"filtered_model_2.obj\", \"w\") as t:\n",
    "            t.writelines(\"mtllib green_mtl.mtl\" + \"\\n\")\n",
    "\n",
    "            for l in pos:\n",
    "                L = \"v \" + str(l[0]) + \" \" + str(l[1]) + \" \" + str(l[2]) + \"\\n\"\n",
    "                t.writelines(L)\n",
    "\n",
    "            # UV 坐标\n",
    "            for i, j in t_array_:\n",
    "                L = \"vt \" + str(i) + \" \" + str(j) + \"\\n\"\n",
    "                t.writelines(L)\n",
    "\n",
    "            t.writelines(\"\\nusemtl green_mtl\\n\")\n",
    "\n",
    "            # 重新写入面\n",
    "            for idx in filtered_face_indices:\n",
    "                p = [idx[0], idx[1], idx[2], idx[3]]\n",
    "                L = \"f \" + \" \".join(f\"{i + 1}/{i + 1}\" for i in p) + \"\\n\"  # 注意 OBJ 文件索引从1开始\n",
    "                t.writelines(L)\n",
    "                \n",
    "    with open(\"my_mtl.mtl\",\"w\") as m:  \n",
    "        m.writelines(\n",
    "    f\"\"\"\n",
    "    newmtl my_mtl\n",
    "    Ka 1 1 1\n",
    "    Kd 1 1 1\n",
    "    d 1\n",
    "    Ns 0\n",
    "    illum 1\n",
    "    map_Kd {pic_name}\n",
    "    \"\"\"\n",
    "        )\n",
    "\n",
    "\n",
    "    with open(\"green_mtl.mtl\",\"w\") as m:  \n",
    "        m.writelines(\n",
    "    f\"\"\"\n",
    "    newmtl green_mtl\n",
    "    Ka 1 1 1\n",
    "    Kd 1 1 1\n",
    "    d 1\n",
    "    Ns 0\n",
    "    illum 1\n",
    "    map_Kd {pic_name}\n",
    "    \"\"\"\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def render_and_save_images(obj_files, texture_files,mask=\"\", image_size=(800, 800)):\n",
    "        # 读取模型\n",
    "\n",
    "        # 创建渲染窗口\n",
    "        render_window = vtk.vtkRenderWindow()       \n",
    "        render_window.SetSize(image_size[0], image_size[1])  # 设置渲染窗口大小 \n",
    " \n",
    "        # 创建左右视角的渲染器\n",
    "        total_pic_count = 36\n",
    "        renderers = []\n",
    "        for i in range(total_pic_count):\n",
    "            renderer = vtk.vtkRenderer()\n",
    "            render_window.AddRenderer(renderer)\n",
    "            renderers.append(renderer)\n",
    "            # 禁用光照\n",
    "            renderer.SetAmbient(100.0, 100.0, 100.0)  # 设置环境光\n",
    "\n",
    "            for obj_file, pic_name in zip(obj_files, texture_files):\n",
    "                # 读取模型\n",
    "                reader = vtk.vtkOBJReader()\n",
    "                reader.SetFileName(obj_file)\n",
    "                reader.Update()\n",
    "                \n",
    "                # 创建一个映射器\n",
    "                mapper = vtk.vtkPolyDataMapper()\n",
    "                mapper.SetInputConnection(reader.GetOutputPort())\n",
    "                \n",
    "                # 创建一个演员\n",
    "                actor = vtk.vtkActor()\n",
    "                actor.SetMapper(mapper)\n",
    "                \n",
    "                # 读取贴图文件\n",
    "                texture = vtk.vtkTexture()\n",
    "                texture_reader = vtk.vtkJPEGReader()  # 假设贴图为JPEG格式\n",
    "                texture_reader.SetFileName(pic_name)  # 根据.mtl文件中的路径设置\n",
    "                texture_reader.Update()\n",
    "                texture.SetInputConnection(texture_reader.GetOutputPort())\n",
    "                \n",
    "                # 将贴图应用到演员\n",
    "                actor.SetTexture(texture)\n",
    "                renderer.AddActor(actor)\n",
    "\n",
    "\n",
    "                actor.GetProperty().SetLighting(False)\n",
    "            # 设置摄像机\n",
    "            camera = vtk.vtkCamera()\n",
    "            \n",
    "            camera.SetFocalPoint(0, 0, 0)\n",
    "            # if i == 0:  # 左视角\n",
    "            #     camera.SetPosition(-2, 0, 30)  # 可以根据需要调整位置\n",
    "            #     camera.SetViewUp(0, -1, 0)\n",
    "            # else:  # 右视角\n",
    "            #     camera.SetPosition(2, 0, 30)  # 右视角位置\n",
    "            #     camera.SetViewUp(0, -1, 0)\n",
    "\n",
    "      \n",
    "            camera.SetPosition(-18+i*1, 0, 25)  # 可以根据需要调整位置\n",
    "            camera.SetViewUp(0, -1, 0)\n",
    "\n",
    "            renderer.SetActiveCamera(camera)\n",
    "\n",
    "            # 添加演员到渲染器\n",
    "            renderer.AddActor(actor)\n",
    "            renderer.SetBackground(0.0, 0.0, 0.0)  # 背景颜色\n",
    "\n",
    "            # 渲染\n",
    "            render_window.Render()\n",
    "\n",
    "            # 保存图像\n",
    "            window_to_image_filter = vtk.vtkWindowToImageFilter()\n",
    "            window_to_image_filter.SetInput(render_window)\n",
    "            window_to_image_filter.ReadFrontBufferOff()  # 读取后台缓冲区\n",
    "            window_to_image_filter.Update()\n",
    "\n",
    "            writer = vtk.vtkPNGWriter()\n",
    "            writer.SetFileName(f'view_{i}'+mask+'.png')\n",
    "            writer.SetInputConnection(window_to_image_filter.GetOutputPort())\n",
    "            # writer.SetCompression(0)  # 设置为0表示无压缩，1表示有压缩（PNG默认是压缩）\n",
    "            writer.Write()\n",
    "            if mask!=\"\":\n",
    "                adjust_contrast_if_brightness_high(f'view_{i}'+mask+'.png', f'view_{i}'+mask+'.png')\n",
    "\n",
    "                refine_pic(f'view_{i}'+'.png',f'view_{i}'+'.png')\n",
    "\n",
    "        # 合并图片\n",
    "        # images = [Image.open(f'view_{i}.png') for i in [0,total_pic_count-1]]\n",
    "        # widths, heights = zip(*(i.size for i in images))\n",
    "\n",
    "        # total_width = sum(widths)\n",
    "        # max_height = max(heights)\n",
    "\n",
    "        # new_image = Image.new('RGB', (total_width, max_height))\n",
    "\n",
    "        # x_offset = 0\n",
    "        # for img in images:\n",
    "        #     new_image.paste(img, (x_offset, 0))\n",
    "        #     x_offset += img.width\n",
    "\n",
    "        # new_image.save(output_file)\n",
    "\n",
    "\n",
    "\n",
    "        # 图片序列\n",
    "        image_files = [f\"view_{i}.png\" for i in range(total_pic_count)]  # [\"view_0.png\", \"view_1.png\", ..., \"view_9.png\"]\n",
    "\n",
    "        # 打开所有图片\n",
    "        images = [Image.open(image_file) for image_file in image_files]\n",
    "\n",
    "        # 将图片转换为 GIF\n",
    "        images[0].save(\n",
    "            'output.gif',\n",
    "            save_all=True,\n",
    "            append_images=images[1:],\n",
    "            duration=100,  # 每帧持续时间，单位为毫秒\n",
    "            loop=0  # 0 表示无限循环\n",
    "    )\n",
    "        \n",
    "    obj_files = [ 'filtered_model_2.obj','filtered_model.obj']\n",
    "    texture_files = [pic_name,pic_name, ]  # 贴图文件名\n",
    "    render_and_save_images(obj_files, texture_files)\n",
    "    # texture_files = ['write_texture.jpg','black_texture.jpg', ]  # 贴图文件名\n",
    "    # render_and_save_images(obj_files, texture_files,mask=\"_mask\")\n",
    "\n",
    "path = \"./\"\n",
    "pic_name = \"Q10.png\"\n",
    "pic23d(pic_name,path,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patching holes...\n",
      "Patched 48 holes\n",
      "Fixing degeneracies and intersections\n",
      "Fixed .obj file saved to output_model_fixed.obj\n"
     ]
    }
   ],
   "source": [
    "import trimesh\n",
    "import pymeshfix\n",
    "import numpy as np\n",
    "\n",
    "def fill_holes_in_obj(input_obj_path, output_obj_path):\n",
    "    # Step 1: Load the .obj file using trimesh\n",
    "    mesh = trimesh.load(input_obj_path, force='mesh')\n",
    "\n",
    "    # Check if the mesh has UV mapping and materials\n",
    "    # if not mesh.visual.uv:\n",
    "    #     raise ValueError(\"The model does not contain UV mapping\")\n",
    "\n",
    "    # # Extract the original UV coordinates and material info\n",
    "    # original_uv = mesh.visual.uv\n",
    "    # original_materials = mesh.visual.material\n",
    "\n",
    "    # Convert trimesh mesh to pymeshfix format\n",
    "    vertices = np.array(mesh.vertices)\n",
    "    faces = np.array(mesh.faces)\n",
    "\n",
    "    # Step 2: Use pymeshfix to fill holes\n",
    "    meshfix = pymeshfix.MeshFix(vertices, faces)\n",
    "    meshfix.repair(verbose=True, joincomp=True, remove_smallest_components=False)\n",
    "\n",
    "    # Get the repaired mesh data\n",
    "    fixed_vertices = meshfix.v\n",
    "    fixed_faces = meshfix.f\n",
    "\n",
    "    # Step 3: Create a new trimesh object with fixed geometry\n",
    "    fixed_mesh = trimesh.Trimesh(vertices=fixed_vertices, faces=fixed_faces)\n",
    "\n",
    "    # Step 4: Re-apply original UV mapping and material\n",
    "    # fixed_mesh.visual.uv = original_uv\n",
    "    # fixed_mesh.visual.material = original_materials\n",
    "\n",
    "    # Step 5: Export the fixed .obj file\n",
    "    fixed_mesh.export(output_obj_path)\n",
    "    print(f\"Fixed .obj file saved to {output_obj_path}\")\n",
    "\n",
    "# Example usage\n",
    "input_obj_path = 'filtered_model.obj'  # Replace with your input .obj file path\n",
    "output_obj_path = 'output_model_fixed.obj'  # Replace with your output .obj file path\n",
    "fill_holes_in_obj(input_obj_path, output_obj_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting pymeshfix\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/0a/76/7c3bd6eb9fa1e8f0580ae18bcc0e5279fd58440a76d6a879cd22630957ae/pymeshfix-0.17.0-cp311-cp311-win_amd64.whl (1.4 MB)\n",
      "     ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.1/1.4 MB 2.0 MB/s eta 0:00:01\n",
      "     -- ------------------------------------- 0.1/1.4 MB 2.0 MB/s eta 0:00:01\n",
      "     -- ------------------------------------- 0.1/1.4 MB 2.0 MB/s eta 0:00:01\n",
      "     ----- ---------------------------------- 0.2/1.4 MB 871.5 kB/s eta 0:00:02\n",
      "     ------- -------------------------------- 0.3/1.4 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 0.4/1.4 MB 1.4 MB/s eta 0:00:01\n",
      "     ----------- ---------------------------- 0.4/1.4 MB 1.2 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 0.5/1.4 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 0.6/1.4 MB 1.5 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 0.6/1.4 MB 1.5 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 0.6/1.4 MB 1.5 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 0.8/1.4 MB 1.5 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 0.9/1.4 MB 1.4 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 0.9/1.4 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 1.0/1.4 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 1.0/1.4 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 1.0/1.4 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 1.0/1.4 MB 1.4 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 1.0/1.4 MB 1.1 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 1.0/1.4 MB 1.1 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 1.1/1.4 MB 1.2 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 1.1/1.4 MB 1.2 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 1.2/1.4 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 1.3/1.4 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 1.3/1.4 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.4/1.4 MB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>1.11.0 in e:\\conda\\envs\\unique3d\\lib\\site-packages (from pymeshfix) (1.26.4)\n",
      "Collecting pyvista>=0.30.0 (from pymeshfix)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e9/ec/ebc65900d1bbc4aec23d15c1d60472565b55ab7c4f9d2bcfba29b8406c38/pyvista-0.44.1-py3-none-any.whl (2.2 MB)\n",
      "     ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.1/2.2 MB 1.1 MB/s eta 0:00:03\n",
      "     -- ------------------------------------- 0.1/2.2 MB 1.2 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 0.2/2.2 MB 1.1 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 0.2/2.2 MB 958.4 kB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 0.3/2.2 MB 1.1 MB/s eta 0:00:02\n",
      "     ----- ---------------------------------- 0.3/2.2 MB 1.1 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 0.4/2.2 MB 1.1 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 0.5/2.2 MB 1.4 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 0.6/2.2 MB 1.3 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 0.6/2.2 MB 1.4 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 0.7/2.2 MB 1.4 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 0.8/2.2 MB 1.5 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 0.9/2.2 MB 1.5 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 0.9/2.2 MB 1.5 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 1.0/2.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 1.0/2.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 1.0/2.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 1.0/2.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 1.0/2.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 1.0/2.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 1.0/2.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 1.2/2.2 MB 1.2 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 1.3/2.2 MB 1.2 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 1.4/2.2 MB 1.3 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 1.4/2.2 MB 1.3 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 1.5/2.2 MB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 1.6/2.2 MB 1.3 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 1.7/2.2 MB 1.3 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 1.8/2.2 MB 1.3 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 1.9/2.2 MB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 1.9/2.2 MB 1.3 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 2.1/2.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.2/2.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.2/2.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.2/2.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.2/2.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.2/2.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.2/2.2 MB 1.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: matplotlib>=3.0.1 in e:\\conda\\envs\\unique3d\\lib\\site-packages (from pyvista>=0.30.0->pymeshfix) (3.9.0)\n",
      "Requirement already satisfied: pillow in e:\\conda\\envs\\unique3d\\lib\\site-packages (from pyvista>=0.30.0->pymeshfix) (10.4.0)\n",
      "Requirement already satisfied: pooch in e:\\conda\\envs\\unique3d\\lib\\site-packages (from pyvista>=0.30.0->pymeshfix) (1.8.2)\n",
      "Collecting scooby>=0.5.1 (from pyvista>=0.30.0->pymeshfix)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/2f/4b/ea1c1c4ecaa97baf8001568d502eaff1bbc3d5c1b48cce3f3fd5a77b8f52/scooby-0.10.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: vtk in e:\\conda\\envs\\unique3d\\lib\\site-packages (from pyvista>=0.30.0->pymeshfix) (9.3.1)\n",
      "Requirement already satisfied: typing-extensions in e:\\conda\\envs\\unique3d\\lib\\site-packages (from pyvista>=0.30.0->pymeshfix) (4.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\conda\\envs\\unique3d\\lib\\site-packages (from matplotlib>=3.0.1->pyvista>=0.30.0->pymeshfix) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\conda\\envs\\unique3d\\lib\\site-packages (from matplotlib>=3.0.1->pyvista>=0.30.0->pymeshfix) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\conda\\envs\\unique3d\\lib\\site-packages (from matplotlib>=3.0.1->pyvista>=0.30.0->pymeshfix) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in e:\\conda\\envs\\unique3d\\lib\\site-packages (from matplotlib>=3.0.1->pyvista>=0.30.0->pymeshfix) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\conda\\envs\\unique3d\\lib\\site-packages (from matplotlib>=3.0.1->pyvista>=0.30.0->pymeshfix) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in e:\\conda\\envs\\unique3d\\lib\\site-packages (from matplotlib>=3.0.1->pyvista>=0.30.0->pymeshfix) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\conda\\envs\\unique3d\\lib\\site-packages (from matplotlib>=3.0.1->pyvista>=0.30.0->pymeshfix) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in e:\\conda\\envs\\unique3d\\lib\\site-packages (from pooch->pyvista>=0.30.0->pymeshfix) (4.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in e:\\conda\\envs\\unique3d\\lib\\site-packages (from pooch->pyvista>=0.30.0->pymeshfix) (2.32.3)\n",
      "Requirement already satisfied: six>=1.5 in e:\\conda\\envs\\unique3d\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.1->pyvista>=0.30.0->pymeshfix) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\conda\\envs\\unique3d\\lib\\site-packages (from requests>=2.19.0->pooch->pyvista>=0.30.0->pymeshfix) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\conda\\envs\\unique3d\\lib\\site-packages (from requests>=2.19.0->pooch->pyvista>=0.30.0->pymeshfix) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\conda\\envs\\unique3d\\lib\\site-packages (from requests>=2.19.0->pooch->pyvista>=0.30.0->pymeshfix) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\conda\\envs\\unique3d\\lib\\site-packages (from requests>=2.19.0->pooch->pyvista>=0.30.0->pymeshfix) (2024.7.4)\n",
      "Installing collected packages: scooby, pyvista, pymeshfix\n",
      "Successfully installed pymeshfix-0.17.0 pyvista-0.44.1 scooby-0.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pymeshfix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import vtk\n",
    "\n",
    "# def render_and_save_images(obj_files, pic_names, output_prefix):\n",
    "#     # 创建渲染窗口\n",
    "#     render_window = vtk.vtkRenderWindow()\n",
    "    \n",
    "#     # 创建左右视角的渲染器\n",
    "#     total_pic_count = 36\n",
    "#     renderers = []\n",
    "    \n",
    "#     for i in range(total_pic_count):\n",
    "#         renderer = vtk.vtkRenderer()\n",
    "#         render_window.AddRenderer(renderer)\n",
    "#         renderers.append(renderer)\n",
    "        \n",
    "#         # 禁用光照\n",
    "#         renderer.SetAmbient(100.0, 100.0, 100.0)  # 设置环境光\n",
    "        \n",
    "#         for obj_file, pic_name in zip(obj_files, pic_names):\n",
    "#             # 读取模型\n",
    "#             reader = vtk.vtkOBJReader()\n",
    "#             reader.SetFileName(obj_file)\n",
    "#             reader.Update()\n",
    "            \n",
    "#             # 创建一个映射器\n",
    "#             mapper = vtk.vtkPolyDataMapper()\n",
    "#             mapper.SetInputConnection(reader.GetOutputPort())\n",
    "            \n",
    "#             # 创建一个演员\n",
    "#             actor = vtk.vtkActor()\n",
    "#             actor.SetMapper(mapper)\n",
    "            \n",
    "#             # 读取贴图文件\n",
    "#             texture = vtk.vtkTexture()\n",
    "#             texture_reader = vtk.vtkJPEGReader()  # 假设贴图为JPEG格式\n",
    "#             texture_reader.SetFileName(pic_name)  # 根据.mtl文件中的路径设置\n",
    "#             texture_reader.Update()\n",
    "#             texture.SetInputConnection(texture_reader.GetOutputPort())\n",
    "            \n",
    "#             # 将贴图应用到演员\n",
    "#             actor.SetTexture(texture)\n",
    "#             renderer.AddActor(actor)\n",
    "        \n",
    "#         # 设置摄像机\n",
    "#         camera = vtk.vtkCamera()\n",
    "#         camera.SetFocalPoint(0, 0, 0)\n",
    "#         camera.SetPosition(-18 + i * 1, 0, 30)  # 可以根据需要调整位置\n",
    "#         camera.SetViewUp(0, -1, 0)\n",
    "#         renderer.SetActiveCamera(camera)\n",
    "\n",
    "#         # 设置背景颜色\n",
    "#         renderer.SetBackground(0.0, 0.0, 0.0)  # 背景颜色\n",
    "\n",
    "#         # 渲染\n",
    "#         render_window.Render()\n",
    "\n",
    "#         # 保存图像\n",
    "#         window_to_image_filter = vtk.vtkWindowToImageFilter()\n",
    "#         window_to_image_filter.SetInput(render_window)\n",
    "#         window_to_image_filter.ReadFrontBufferOff()  # 读取后台缓冲区\n",
    "#         window_to_image_filter.Update()\n",
    "\n",
    "#         writer = vtk.vtkPNGWriter()\n",
    "#         writer.SetFileName(f'{output_prefix}_view_{i}.png')\n",
    "#         writer.SetInputConnection(window_to_image_filter.GetOutputPort())\n",
    "#         writer.Write()\n",
    "\n",
    "# # 使用示例\n",
    "# obj_files = ['filtered_model.obj', 'filtered_model_2.obj']\n",
    "# pic_names = ['Q8.jpg', 'green_texture.jpg']  # 对应的贴图文件\n",
    "# render_and_save_images(obj_files, pic_names, 'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-10 02:22:07,825 - modelscope - WARNING - Model revision not specified, use revision: v1.0.0\n",
      "2024-10-10 02:22:08,191 - modelscope - INFO - initiate model from C:\\Users\\Administrator\\.cache\\modelscope\\hub\\damo\\cv_fft_inpainting_lama\n",
      "2024-10-10 02:22:08,191 - modelscope - INFO - initiate model from location C:\\Users\\Administrator\\.cache\\modelscope\\hub\\damo\\cv_fft_inpainting_lama.\n",
      "2024-10-10 02:22:08,191 - modelscope - INFO - initialize model from C:\\Users\\Administrator\\.cache\\modelscope\\hub\\damo\\cv_fft_inpainting_lama\n",
      "2024-10-10 02:22:08,236 - modelscope - INFO - BaseInpaintingTrainingModule init called, predict_only is False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights for net_encoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-10 02:22:09,441 - modelscope - INFO - BaseInpaintingTrainingModule init done\n",
      "2024-10-10 02:22:09,441 - modelscope - INFO - loading pretrained model from C:\\Users\\Administrator\\.cache\\modelscope\\hub\\damo\\cv_fft_inpainting_lama\\pytorch_model.pt\n",
      "2024-10-10 02:22:10,245 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-10-10 02:22:10,245 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-10-10 02:22:10,245 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': 'C:\\\\Users\\\\Administrator\\\\.cache\\\\modelscope\\\\hub\\\\damo\\\\cv_fft_inpainting_lama'}. trying to build by task and model information.\n",
      "2024-10-10 02:22:10,245 - modelscope - WARNING - No preprocessor key ('FFTInpainting', 'image-inpainting') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "2024-10-10 02:22:10,261 - modelscope - INFO - loading model from dir C:\\Users\\Administrator\\.cache\\modelscope\\hub\\damo\\cv_fft_inpainting_lama\n",
      "2024-10-10 02:22:10,261 - modelscope - INFO - BaseInpaintingTrainingModule init called, predict_only is True\n",
      "2024-10-10 02:22:12,284 - modelscope - INFO - BaseInpaintingTrainingModule init done\n",
      "2024-10-10 02:22:12,285 - modelscope - INFO - loading pretrained model from C:\\Users\\Administrator\\.cache\\modelscope\\hub\\damo\\cv_fft_inpainting_lama\\pytorch_model.pt\n",
      "2024-10-10 02:22:12,858 - modelscope - INFO - loading model done, refinement is set to False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import cv2\n",
    "# from modelscope.outputs import OutputKeys\n",
    "# from modelscope.pipelines import pipeline\n",
    "# from modelscope.utils.constant import Tasks\n",
    "\n",
    "# input_location = './view_2.png'\n",
    "# input_mask_location = './view_2_mask.png'\n",
    "\n",
    "# input = {\n",
    "#         'img':input_location,\n",
    "#         'mask':input_mask_location,\n",
    "# }\n",
    "\n",
    "# inpainting = pipeline(Tasks.image_inpainting, model='damo/cv_fft_inpainting_lama', refine=True)\n",
    "# result = inpainting(input)\n",
    "# vis_img = result[OutputKeys.OUTPUT_IMG]\n",
    "# cv2.imwrite('result.png', vis_img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
